"""
FinBERT æ¨¡å‹æœåŠ¡
è´Ÿè´£åŠ è½½æ¨¡å‹ã€tokenizer å’Œæ‰§è¡Œæ¨ç†
"""
import torch
import torch.nn.functional as F
from transformers import BertTokenizer, BertForSequenceClassification
from typing import Dict


class FinBERTService:
    """FinBERT æ¨¡å‹æœåŠ¡ç±»"""
    
    def __init__(self):
        self.model = None
        self.tokenizer = None
        self.model_name = "ProsusAI/finbert"
        self.is_loaded = False
        
        # FinBERT æ ‡ç­¾æ˜ å°„
        self.labels_map = {
            0: "Positive",   # åˆ©å¥½
            1: "Negative",   # åˆ©ç©º
            2: "Neutral"     # ä¸­æ€§
        }
    
    def load_model(self):
        """
        åŠ è½½ FinBERT æ¨¡å‹å’Œ tokenizer
        """
        if self.is_loaded:
            print("âš ï¸  æ¨¡å‹å·²åŠ è½½ï¼Œè·³è¿‡é‡å¤åŠ è½½")
            return
        
        try:
            print(f"ğŸ“¦ æ­£åœ¨åŠ è½½æ¨¡å‹: {self.model_name}")
            print("â³ é¦–æ¬¡åŠ è½½å¯èƒ½éœ€è¦ä¸‹è½½æ¨¡å‹æ–‡ä»¶ï¼Œè¯·ç¨å€™...")
            
            # åŠ è½½åˆ†è¯å™¨
            self.tokenizer = BertTokenizer.from_pretrained(self.model_name)
            
            # åŠ è½½æ¨¡å‹ï¼ˆç”¨äºåºåˆ—åˆ†ç±»ï¼‰
            self.model = BertForSequenceClassification.from_pretrained(self.model_name)
            
            # è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼ï¼ˆå…³é—­ dropout ç­‰è®­ç»ƒç‰¹æ€§ï¼‰
            self.model.eval()
            
            self.is_loaded = True
            print("âœ… æ¨¡å‹åŠ è½½æˆåŠŸï¼")
            
        except Exception as e:
            print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {str(e)}")
            self.is_loaded = False
            raise
    
    def classify_text(self, text: str, temperature: float = 1.2, top_k: int = 5) -> Dict[str, any]:
        """æ‰§è¡Œæ ‡å‡†åŒ–è´¢ç»åˆ†ç±»æ¨ç†å¹¶è¿”å›ç»“æ„åŒ–ç»“æœã€‚

        Args:
            text: å¾…åˆ†ç±»æ–‡æœ¬
            temperature: æ¸©åº¦ç¼©æ”¾å‚æ•° (é»˜è®¤ 1.2)
            top_k: Top-k äº‹ä»¶ç±»å‹è¿”å›æ•°é‡

        Returns:
            {
              "classification": {"market_direction": ..., "event_type": ..., "impact_strength": ..., "risk_signal": ...},
              "top_k": [{"label": str, "score": float}, ...]
            }
        """
        if not self.is_loaded:
            raise RuntimeError("æ¨¡å‹æœªåŠ è½½ï¼Œè¯·å…ˆè°ƒç”¨ load_model()")

        if not text or not text.strip():
            raise ValueError("è¾“å…¥æ–‡æœ¬ä¸èƒ½ä¸ºç©º")

        try:
            inputs = self.tokenizer(
                text,
                return_tensors="pt",
                padding=True,
                truncation=True,
                max_length=512
            )

            with torch.no_grad():
                outputs = self.model(**inputs)

            logits = outputs.logits[0]  # shape [3]

            # æ˜¾å¼æ¸©åº¦ç¼©æ”¾ä¸ softmaxï¼ˆæ»¡è¶³è§„èŒƒè¦æ±‚ï¼‰â€”â€”ç»“æœä»…ç”¨äºå†…éƒ¨éªŒè¯ï¼Œä¸ç›´æ¥è¿”å›
            if temperature <= 0:
                raise ValueError("temperature å¿…é¡» > 0")
            scaled_logits = logits / temperature
            _ = F.softmax(scaled_logits, dim=-1)  # è®¡ç®—åä¸å¤–éœ²ï¼Œæœ€ç»ˆæ˜ å°„äº¤ç”± label_mapper

            from .label_mapper import map_finbert_logits_to_labels
            mapped = map_finbert_logits_to_labels(logits, top_k=top_k, temperature=temperature)
            return mapped

        except Exception as e:
            print(f"âŒ åˆ†ç±»è¿‡ç¨‹å‡ºé”™: {str(e)}")
            raise


# åˆ›å»ºå…¨å±€æœåŠ¡å®ä¾‹
bert_service = FinBERTService()

